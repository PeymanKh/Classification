{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification Template\n",
        "**Author:** Peyman Kh\n",
        "\n",
        "**Date:** YYYY-MM-DD  \n",
        "\n",
        "**Task:** Image classification with TensorFlow/Keras  \n",
        "\n",
        "**Dataset:** [Dataset Name or Link]  \n"
      ],
      "metadata": {
        "id": "ulqd4rMlGg3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q7rMVGoGSJh",
        "outputId": "7d9fc514-c0a8-440d-afa3-09e34af4149e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Print TensorFlow version\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# List available physical devices (GPU or CPU)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"Using GPU:\", gpus)\n",
        "else:\n",
        "    print(\"Using CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and setup"
      ],
      "metadata": {
        "id": "Ba5kTQgzIMnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "qfmJIaArG8-P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "def set_seed(seed=42):\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    print(f\"Random seeds set to {seed}.\")\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4-XizmzHNPI",
        "outputId": "ad2040b5-af5e-4b49-c448-06ba173d2a28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seeds set to 42.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config & Hyperparameters"
      ],
      "metadata": {
        "id": "oLcwiwBJIq6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    DATA_DIR = 'data/dataset_name'\n",
        "    IMG_SIZE = (224, 224)\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 20\n",
        "    LR = 1e-4\n",
        "    SEED = 42\n",
        "    NUM_CLASSES = 2"
      ],
      "metadata": {
        "id": "2OUhsWYfIrUX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading and preprocessing"
      ],
      "metadata": {
        "id": "h6hE7dZMIgSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = image_dataset_from_directory(\n",
        "    Config.DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=Config.SEED,\n",
        "    image_size=Config.IMG_SIZE,\n",
        "    batch_size=Config.BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    Config.DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=Config.SEED,\n",
        "    image_size=Config.IMG_SIZE,\n",
        "    batch_size=Config.BATCH_SIZE\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# Prefetch for performance\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "TbNynTcSH_x3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definition"
      ],
      "metadata": {
        "id": "YCT2C6weJOeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=Config.IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(Config.NUM_CLASSES, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeW1CEyUI7h8",
        "outputId": "6e89e163-0352-4380-c263-be72f5c94fe1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile & Train"
      ],
      "metadata": {
        "id": "pj0d5IZ1JaiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=Config.LR),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=3, restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=Config.EPOCHS,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "rEpwMLI_JWLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation & Visualization"
      ],
      "metadata": {
        "id": "ecCWPezUJf3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train')\n",
        "    plt.plot(history.history['val_loss'], label='Val')\n",
        "    plt.title('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "niJPh-5YJgMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix & Classification Report"
      ],
      "metadata": {
        "id": "tQSTe8rNJuuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z4f3NcnAJvHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving & Loading Model"
      ],
      "metadata": {
        "id": "0cbAZxu2Jz6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n",
        "# Load later:\n",
        "# model = tf.keras.models.load_model('model.h5')"
      ],
      "metadata": {
        "id": "njylfRWEJ0QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Next Steps\n",
        "- Unfreeze top layers of the base model (fine-tuning)\n",
        "- Add more data augmentation\n",
        "- Try different architectures (EfficientNet, ViT)\n",
        "- Convert to TF Lite for deployment\n"
      ],
      "metadata": {
        "id": "KOJ7jPOpJ5hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yR8xBRviJ7L5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}